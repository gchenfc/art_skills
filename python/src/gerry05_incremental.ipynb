{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gtsam\n",
    "from gtsam.symbol_shorthand import X, P\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import tqdm\n",
    "import chebyshev_fitter, spline_fitter, sln_letter_fit\n",
    "from sln_letter_fit import FitParams, OptimizationLoggingParams\n",
    "from sln_stroke_fit import SlnStrokeFit\n",
    "from art_skills import SlnStrokeExpression\n",
    "import loader\n",
    "from fit_types import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport chebyshev_fitter, spline_fitter, sln_letter_fit, loader, sln_stroke_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Pretend we already have the stroke splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = loader.load_segments('D')\n",
    "dt = 1./120\n",
    "fit_params = FitParams()\n",
    "fitter = SlnStrokeFit(dt,\n",
    "                      integration_noise_model=gtsam.noiseModel.Isotropic.Sigma(2, fit_params.noise_integration_std),\n",
    "                      data_prior_noise_model=gtsam.noiseModel.Isotropic.Sigma(2, fit_params.noise_data_prior_std),\n",
    "                      reparameterize=fit_params.reparameterize,\n",
    "                      flip_parameters_at_end=fit_params.flip_parameters_at_end)\n",
    "stroke_indices = fitter.stroke_indices(letter)\n",
    "stroke_param_mean, stroke_param_prior = (np.array([\n",
    "    -0.3824788860477358, 0.4333073800807866, 0.3254905871611055, 0.20628570778082297,\n",
    "    0.23762343512462863, -1.104228059293241\n",
    "]), gtsam.noiseModel.Isotropic.Sigma(6, 50))\n",
    "isam2params = gtsam.ISAM2Params()\n",
    "isam2params.evaluateNonlinearError = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "isam = gtsam.ISAM2(isam2params)\n",
    "prev_error = 0\n",
    "estimates = []\n",
    "with tqdm.tnrange(sum(stroke.shape[0] for stroke in letter)) as progress_bar:\n",
    "    progress_bar.set_description('Optimizing stroke')\n",
    "    for strokei, stroke in enumerate(letter):\n",
    "        for datai, (t, x, y) in enumerate(stroke):\n",
    "            # New factors\n",
    "            graph = gtsam.NonlinearFactorGraph()\n",
    "            graph.push_back(fitter.data_prior_factors(np.array([[t, x, y]])))\n",
    "            if k > 0:\n",
    "                graph.push_back(fitter.stroke_factors(strokei, k - 1, k))\n",
    "            if datai == 0:\n",
    "                graph.addPriorVector(P(strokei), stroke_param_mean, stroke_param_prior)\n",
    "            # New variables\n",
    "            init = gtsam.Values()\n",
    "            if datai == 0:\n",
    "                init.insert(P(strokei), stroke_param_mean)\n",
    "            if k == 0:\n",
    "                init.insert(X(k), np.array([x, y]))\n",
    "            else:\n",
    "                stroke_params = isam.calculateEstimateVector(P(strokei if datai > 0 else strokei - 1))\n",
    "                stroke_eval = SlnStrokeExpression(stroke_params)\n",
    "                xy_init = isam.calculateEstimatePoint2(X(k-1)) + stroke_eval.displacement(t, dt)\n",
    "                init.insert(X(k), xy_init)\n",
    "            # update\n",
    "            result = isam.update(graph, init)\n",
    "            # for _ in range(100):\n",
    "            #     isam.update()\n",
    "            def criteria(before, after):\n",
    "                if before == 0:\n",
    "                    return True\n",
    "                return (after * (k-1) / k - before) / before < 1e-2\n",
    "            did_update = 0\n",
    "            for _ in range(20):\n",
    "                if criteria(prev_error, result.getErrorAfter()):\n",
    "                    break\n",
    "                # print(f'error too large: {result.getErrorAfter()}')\n",
    "                result = isam.update()\n",
    "\n",
    "                b, a = prev_error, result.getErrorAfter()\n",
    "                if a != did_update:\n",
    "                    did_update = a\n",
    "                    adjCost = (a * (k - 1) / k - b) / b if k > 0 else float('nan')\n",
    "                    progress_bar.set_postfix(errorBefore=f'{result.getErrorBefore():.2e}',\n",
    "                                            errorAfter=f'{result.getErrorAfter():.2e}',\n",
    "                                            adjustedCostIncrease=f'{adjCost:.3f}')\n",
    "            prev_error = result.getErrorAfter()\n",
    "            estimates.append(isam.calculateEstimate())\n",
    "\n",
    "            # result.print(f'{k = }, error = {result.getErrorBefore()} {result.getErrorAfter()}')\n",
    "            k += 1\n",
    "            progress_bar.update()\n",
    "            # print(isam.calculateEstimate())\n",
    "        break\n",
    "        # graph = gtsam.NonlinearFactorGraph()\n",
    "        # graph.addPriorVector(X(k - 1), np.array([x, y]), gtsam.noiseModel.Isotropic.Sigma(2, 0.05))\n",
    "        # isam.update(graph, gtsam.Values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sol(values, num_strokes, k):\n",
    "    stroke_indices_ = {0: (stroke_indices[0][0], k)}\n",
    "    t = np.arange(0, (k + 1) * dt, dt).reshape(-1, 1)\n",
    "    x0 = fitter.query_estimate_at(values, 0)\n",
    "    def query(t):\n",
    "        try:\n",
    "            return fitter.query_estimate_at(values, t)\n",
    "        except:\n",
    "            return np.zeros((1, 2))#x0\n",
    "    txy = np.hstack((t, [query(t_) for t_ in t]))\n",
    "    num_strokes = sum(1 for start, _ in stroke_indices.values() if k > start)\n",
    "    params = [fitter.query_parameters(values, strokei) for strokei in range(num_strokes)]\n",
    "    txy_from_params = fitter.compute_trajectory_from_parameters(x0, params, stroke_indices)\n",
    "    txy_from_params = np.hstack((np.arange(0, txy_from_params.shape[0] * dt,\n",
    "                                           dt).reshape(-1, 1), txy_from_params))\n",
    "    return Solution(params=params,\n",
    "                    txy=txy,\n",
    "                    txy_from_params=txy_from_params,\n",
    "                    stroke_indices=stroke_indices_)\n",
    "history = [create_sol(estimate, 1, kmax) for kmax, estimate in enumerate(estimates)]\n",
    "sol_and_history = (history[-1], history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "txy_gt = np.vstack(letter)\n",
    "def update(i):\n",
    "    ax.cla()\n",
    "    ax.plot(txy_gt[:i + 1, 1], txy_gt[:i + 1, 2], 'k.')\n",
    "    est = history[i]\n",
    "    ax.plot(est['txy'][:i + 1, 1], est['txy'][:i + 1, 2], 'r.', markersize=1)\n",
    "    ax.plot(est['txy_from_params'][:i + 1, 1],\n",
    "            est['txy_from_params'][:i + 1, 2],\n",
    "            'r-',\n",
    "            markersize=1)\n",
    "    ax.plot(est['txy_from_params'][i:i + 10, 1],\n",
    "            est['txy_from_params'][i:i + 10, 2],\n",
    "            'b-',\n",
    "            markersize=1)\n",
    "\n",
    "    text = '\\n'.join(f'params: ' + ''.join(f'{param:6.2f}'.replace(' ', '~')\n",
    "                                           for param in params)\n",
    "                     for params in history[i]['params'])\n",
    "    text_box = matplotlib.offsetbox.AnchoredText(text,\n",
    "                                                 frameon=True,\n",
    "                                                 loc='lower right',\n",
    "                                                 pad=0.3,\n",
    "                                                 bbox_to_anchor=(1, 0),\n",
    "                                                 bbox_transform=ax.transAxes,\n",
    "                                                 borderpad=0,\n",
    "                                                 prop=dict(size=9))\n",
    "    text_box.patch.set_alpha(0.4)\n",
    "    ax.add_artist(text_box)\n",
    "\n",
    "    ax.axis('equal')\n",
    "    ax.set_ylim(-1.1, -0.1)\n",
    "\n",
    "# with tqdm.notebook.trange(0, len(letter[0]), 1) as progress_bar:\n",
    "#     progress_bar.set_description('Saving Animation')\n",
    "#     anim = matplotlib.animation.FuncAnimation(ax.figure, update, frames=progress_bar)\n",
    "#     anim.save('results/incremental_D_stroke0.mp4', writer=matplotlib.animation.FFMpegWriter(fps=15))\n",
    "# anim = plotting.animate_trajectories(ax, [letter], [sol_and_history], is_notebook=True)\n",
    "with tqdm.notebook.trange(0, len(history), 1) as progress_bar:\n",
    "    progress_bar.set_description('Displaying Animation')\n",
    "    anim = matplotlib.animation.FuncAnimation(ax.figure, update, frames=progress_bar)\n",
    "    plt.close(fig)\n",
    "    display(HTML(anim.to_jshtml()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "402f513bd64bb05ccdfd11315d0c88453571d1d1d73db48414a1b2a41f771ebc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
